# data-mining
CF协同过滤算法实现方法


（1）算法选择
选择了CF——协同过滤之后，我便开始对比User－based算法与Item－based算法，也在网上找了一些参考资料，通过对比两个Item在八万行不同用户对不同电影数据集中的差异性与相似性，来预测用户对某部电影对最终评分。
（2）实现问题与困难
开始我选择了Python语言来进行编程，也研究了SVD＋＋算法，但是后来因为一些原因还是放弃了：
1.Python是脚本语言，编译速率太慢，仅仅是导入txt的数据进行简单计算，短短几百行代码居然跑了我整整十分钟。
2.对于Python的用法还是不够熟悉，开发效率低下，总是要查阅一些例如字典、IO操作的语法，本身想通过python的语法简洁性来训练自己的编程能力，不得不因为效率太低放弃。
3.我对SVD＋＋算法步骤理解不清，且实现的方法不是很明确，可参考的资料太少。


最后还是选择了C++来实现，没有借用任何第三方类库。我听到许多同学使用了一个叫c++／java  map的东西，也就是一个c++标准容器，其实原理上就是map multimap提供了一个键对应多个值，和python中的字典比较相似，在用户id、电影id、打分之间可以形成类似于spl中的关联关系。我没有使用map，而是用c++基础的语法去完成。
（3）核心部分
我将训练集数据导入一个二维数组train_info中，第一个下标i为用户id，第二个j为电影id，那么train_info［i］［j］＝i对j的打分。拥有了这个数组，我不仅可以算出每一个用户对所有电影打的分，还可以算出每一个用户与其他用户的相似性，最后得到一个N＊N的相似矩阵similarity_matrix［i］［j］，顾名思义，就是i用户与j用户的相似性，算法公式：

 
矩阵的存在直接决定了我可以安心地来计算二维矩阵predicting_score[i][j]，同样记录了i对j的打分。但是在这之前，问题来了——有个很重要的工作就是，我在计算一个用户的预测分时，我应该选择谁去作为他的邻居呢？
于是我想到，用KNN算法，刚好可以解决这个问题，但是这个部分是最容易出现误差的。所以，我会设置一个“门槛”，在计算时，只有与该用户相似性大于“门槛”值的用户才会进行预测分的计算。这样可以保证计算的正确性。
那么问题又来了，如果该用户没有相似性大于该“门槛”的邻居呢？那么，这样，我想到了一个解决方案，继续计算第二级“门槛”，如果不行，继续计算下一个……这样可以避免有些用户没有邻居，而无法预测分数。
然后就是计算预测分了，预测分的计算一目了然：
 
所有预测分被存到数组predicting_score[i][j]之中，最后，用来被和actual_score[i][j]中每一个对应的数据作对比，计算MAE和RMSE：
 
 
最后算出，MAE的结果是：0.717，RMAE的结果是1.053。
（4）结果分析
对于MAE和RMSE的结果，我进行了部分改进，但是还是变动较少。MAE偏高，可能的问题在于，KNN步骤中设置“门槛”的方法一定程度上存在较大误差，如果不存在目标“邻居”，那么需要用一个相对科学的方法来减小误差。门槛太高，容易找不到“邻居”，门槛太低，容易计算生成较大误差。所以这部分，我之前作的改进力度还不够。

后记
    在这次数据挖掘大作业中，我收获颇丰。一个人完成所有工作真的不容易。但是，我还是很多同学请教、交流了彼此的想法和计划。如何用代码实现一套科学的算法。该系统的应用范围很广，比如商品推荐、淘宝、豆瓣音乐、电影评分、美食评分等等。现代人类的生活离不开数据，也绝对不能和数据相分离，只有在万千数据中，利用科学的计算方法去减小误差，才能获得最为珍贵的结果。这次大作业还锻炼了我的编程能力和算法理解能力，如何将抽象的算法转化为实际的代码，这是一个优秀的程序员应该拥有的素质。我还会继续学习数据挖掘的知识，丰富自己，在计算机软件道路上深入下去。
